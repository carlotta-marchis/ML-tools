{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define a function that performs a parameter tuning using `GridSearchCV` and returns the `best_params` and the `best_estimator` of the grid search.\n",
    "\n",
    "I will use the data from the Kaggle's Titanic competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the data\n",
    "data = pd.read_csv('../Kaggle competitions/Titanic/input/train.csv')\n",
    "data.pop('Cabin') # Dropping 'Cabin' column as too many entries are missing\n",
    "data.pop('Name') # Dropping the 'Name' column as it requires preprocessing\n",
    "data.pop('Ticket') # Dropping the 'Ticket' column as it requires preprocessing\n",
    "data.pop('PassengerId') # Dropping the 'PassengerId' column as it is equal to row.index+1 \n",
    "data['Age'] = data['Age'].fillna(data['Age'].mean()) # Filling missing Age values with mean\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()) # Filling missing 'Embarked' values with mode (most frequent value)\n",
    "data['Pclass'] = data['Pclass'].apply(str) # Converting the entries of the cathegorical column 'Pclass' into strings\n",
    "data = pd.get_dummies(data, prefix_sep='_') # Encoding cathegorical data\n",
    "y = data['Survived'] # Target array\n",
    "X = data.drop(['Survived'], axis=1) # Features matrix\n",
    "\n",
    "# Splitting the data into train and test subsets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define the `parameter_tuning` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def parameter_tuning(model, Xtrain, ytrain, param_grid, cv=5, n_jobs=1):\n",
    "    \"\"\"This function returns the best_parameter and the best estimator of the grid search\n",
    "    Note: the param_grid must be defined accordingly to the model tested\"\"\"\n",
    "    \n",
    "    gs = GridSearchCV(model, param_grid, cv=cv, verbose=1, n_jobs=n_jobs)\n",
    "    gs.fit(Xtrain, ytrain)\n",
    "    \n",
    "    return gs.best_params_, gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example I will use the `KNeighborsClassifier` estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Number of neighbors to use by default for kneighbors queries.\n",
    "n_neighbors = [3, 5, 11, 19, 21]\n",
    "# Weight function used in prediction. \n",
    "weights = ['uniform', 'distance']\n",
    "# The distance metric to use for the tree.\n",
    "metrics = ['euclidean', 'minkowski', 'manhattan']\n",
    "# Algorithm used to copute the nearest neighbor\n",
    "algorithms = ['ball_tree', 'kd_tree', 'brute']\n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors,\n",
    "              'weights': weights,\n",
    "              'metric': metrics,\n",
    "              'algorithm': algorithms}\n",
    "\n",
    "best_params, KNN_tuned = parameter_tuning(KNeighborsClassifier(), Xtrain, ytrain, param_grid, 5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute',\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 19,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_model = KNN_tuned.fit(Xtrain, ytrain).predict(Xtest)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       140\n",
      "           1       0.64      0.70      0.67        83\n",
      "\n",
      "    accuracy                           0.74       223\n",
      "   macro avg       0.73      0.74      0.73       223\n",
      "weighted avg       0.75      0.74      0.75       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(ytest, y_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
